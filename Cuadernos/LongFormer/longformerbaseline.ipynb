{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef9d1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa la biblioteca pandas, utilizada para manipular y analizar datos estructurados como tablas (dataframes).\n",
    "import pandas as pd\n",
    "\n",
    "# Importa la biblioteca re, que se usa para trabajar con expresiones regulares (útil para manipular y analizar texto).\n",
    "import re\n",
    "\n",
    "# Importa herramientas específicas de la biblioteca transformers de Hugging Face:\n",
    "# - BertTokenizer: Tokenizador preentrenado para el modelo BERT, convierte texto en entradas numéricas.\n",
    "# - BertForSequenceClassification: Modelo BERT preentrenado adaptado para tareas de clasificación de secuencias.\n",
    "# - Trainer y TrainingArguments: Herramientas para configurar y ejecutar el proceso de entrenamiento de modelos.\n",
    "# - EarlyStoppingCallback: Callback para detener el entrenamiento si no mejora después de ciertos pasos.\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback, AutoTokenizer, AutoModelForSequenceClassification, pipeline, EarlyStoppingCallback, RobertaTokenizer, RobertaForSequenceClassification\n",
    "\n",
    "# Importa PyTorch, una biblioteca de Machine Learning que se utiliza para definir y entrenar redes neuronales.\n",
    "import torch\n",
    "\n",
    "# Importa train_test_split de scikit-learn, usado para dividir un conjunto de datos en subconjuntos de entrenamiento y prueba.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importa DataLoader y Dataset de PyTorch, que se usan para manejar y cargar datos en lotes durante el entrenamiento.\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Importa classification_report de scikit-learn, que genera un informe con métricas de evaluación como precisión, recuperación y F1.\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, f1_score, average_precision_score, accuracy_score, precision_recall_fscore_support, precision_score, recall_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aca7847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la ruta base del proyecto.\n",
    "path = ''\n",
    "\n",
    "# Definimos los nombres de las columnas clave del dataset:\n",
    "COLUMN_ID = 'id'               # Identificador único para cada muestra\n",
    "COLUMN_LETRA = 'lyrics'       # Columna con la letra de la canción\n",
    "COLUMN_ETIQUETA = 'label'     # Etiqueta de clase (0 = No Misógina, 1 = Misógina)\n",
    "COLUMN_RAZONAMIENTO = 'reasoning'  # Columna con el razonamiento explicativo (Chain of Thought)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35ca6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Cargamos el dataset con razonamientos generados por GPT-4o\n",
    "dfTotal = pd.read_csv(f'{path}/../data/train_data/task1_GPT4o_dataReasoning.csv')\n",
    "\n",
    "# Dividimos el dataset original en entrenamiento y test (80% - 20%) de forma estratificada\n",
    "train_df_temp, test_df = train_test_split(\n",
    "    dfTotal,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=dfTotal[COLUMN_ETIQUETA]\n",
    ")\n",
    "\n",
    "# A partir del conjunto de entrenamiento temporal, extraemos validación (20% de train) también estratificado\n",
    "train_df, valid_df = train_test_split(\n",
    "    train_df_temp,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=train_df_temp[COLUMN_ETIQUETA]\n",
    ")\n",
    "\n",
    "# Mostramos la distribución de clases en cada subconjunto antes de aplicar balanceo\n",
    "print(\"\\n--- Distribución de Clases ---\")\n",
    "print(\"Conjunto de Entrenamiento:\")\n",
    "print(train_df[COLUMN_ETIQUETA].value_counts(normalize=False))\n",
    "\n",
    "print(\"\\nConjunto de Validación:\")\n",
    "print(valid_df[COLUMN_ETIQUETA].value_counts(normalize=False))\n",
    "\n",
    "print(\"\\nConjunto de Test:\")\n",
    "print(test_df[COLUMN_ETIQUETA].value_counts(normalize=False))\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "# Separamos las clases en el conjunto de entrenamiento para aplicar oversampling\n",
    "majority_class_df = train_df[train_df[COLUMN_ETIQUETA] == 0]\n",
    "minority_class_df = train_df[train_df[COLUMN_ETIQUETA] == 1]\n",
    "\n",
    "# Aplicamos oversampling a la clase minoritaria para mejorar el balance de clases\n",
    "minority_oversampled_df = resample(\n",
    "    minority_class_df,\n",
    "    replace=True,        # Permitimos duplicados\n",
    "    n_samples=600,       # Tamaño fijo para clase minoritaria (aprox. 60-40%)\n",
    "    # n_samples=len(majority_class_df),  # Alternativa: igualar tamaños de ambas clases\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Combinamos el conjunto mayoritario original con la versión sobremuestreada del minoritario\n",
    "train_df_balanced = pd.concat([majority_class_df, minority_oversampled_df])\n",
    "\n",
    "# Mostramos la nueva distribución tras el balanceo\n",
    "print(\"\\nConjunto de Entrenamiento Nuevo:\")\n",
    "print(train_df_balanced[COLUMN_ETIQUETA].value_counts(normalize=False))\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "# Barajamos el conjunto para evitar que las clases queden agrupadas\n",
    "train_df_balanced = train_df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7fa267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Convertimos los DataFrames de pandas a objetos Dataset de Hugging Face.\n",
    "# Esto es necesario para usarlos con modelos y entrenadores de la librería transformers.\n",
    "\n",
    "train_data = Dataset.from_pandas(train_df_balanced)  # Dataset de entrenamiento balanceado\n",
    "valid_data = Dataset.from_pandas(valid_df)           # Dataset de validación (sin modificar)\n",
    "test_data = Dataset.from_pandas(test_df)             # Dataset de test (sin modificar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c81f1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LongformerTokenizer\n",
    "\n",
    "# Cargamos el tokenizador de Longformer entrenado con BETO en español\n",
    "# Este modelo permite entradas largas (hasta 4096 tokens) y es útil para procesar letras extensas\n",
    "tokenizer = AutoTokenizer.from_pretrained('PlanTL-GOB-ES/longformer-base-4096-bne-es')\n",
    "\n",
    "# Definimos una función para tokenizar cada ejemplo del dataset\n",
    "def tokenizeFunction(example):\n",
    "    tokens = tokenizer(\n",
    "        example[COLUMN_LETRA],       # Tokenizamos la letra de la canción\n",
    "        padding=\"max_length\",        # Añadimos padding hasta la longitud máxima\n",
    "        truncation=True,             # Truncamos si la entrada es más larga de lo permitido\n",
    "        max_length=1024              # Limitamos a 1024 tokens (aunque el modelo permite hasta 4096)\n",
    "    )\n",
    "    \n",
    "    # Longformer requiere una máscara de atención global.\n",
    "    # Aquí activamos atención global solo en el primer token\n",
    "    tokens[\"global_attention_mask\"] = [0] * len(tokens[\"input_ids\"])\n",
    "    tokens[\"global_attention_mask\"][0] = 1\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e44d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Análisis exploratorio: distribución de longitud de las letras tokenizadas ---\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculamos la longitud (número de tokens) de cada letra en el conjunto de entrenamiento\n",
    "# No añadimos tokens especiales aún, solo los tokens reales de contenido\n",
    "token_lengths = [len(tokenizer.encode(text, add_special_tokens=False)) for text in train_df[COLUMN_LETRA].astype(str)]\n",
    "\n",
    "# Creamos un histograma para visualizar la distribución de longitudes\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(token_lengths, bins=50, alpha=0.7)\n",
    "\n",
    "# Añadimos líneas verticales de referencia para longitudes típicas\n",
    "plt.axvline(128, color='red', linestyle='dashed', linewidth=1, label='Max Length = 128')\n",
    "plt.axvline(256, color='orange', linestyle='dashed', linewidth=1, label='Max Length = 256')\n",
    "plt.axvline(384, color='green', linestyle='dashed', linewidth=1, label='Max Length = 384')\n",
    "plt.axvline(512, color='blue', linestyle='dashed', linewidth=1, label='Max Length = 512')\n",
    "plt.axvline(1024, color='black', linestyle='dashed', linewidth=1, label='Max Length = 1024')\n",
    "\n",
    "# Añadimos etiquetas y leyenda al gráfico\n",
    "plt.xlabel('Número de Tokens (sin padding/truncation)')\n",
    "plt.ylabel('Número de Canciones')\n",
    "plt.title('Distribución de Longitud de Tokens de las Letras')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Imprimimos estadísticas de interés: porcentaje de letras que superan ciertas longitudes\n",
    "print(f\"Porcentaje de canciones con más de 128 tokens: {sum(l > 128 for l in token_lengths) / len(token_lengths) * 100:.2f}%\")\n",
    "print(f\"Porcentaje de canciones con más de 256 tokens: {sum(l > 256 for l in token_lengths) / len(token_lengths) * 100:.2f}%\")\n",
    "print(f\"Porcentaje de canciones con más de 384 tokens: {sum(l > 384 for l in token_lengths) / len(token_lengths) * 100:.2f}%\")\n",
    "print(f\"Porcentaje de canciones con más de 512 tokens: {sum(l > 512 for l in token_lengths) / len(token_lengths) * 100:.2f}%\")\n",
    "print(f\"Porcentaje de canciones con más de 1024 tokens: {sum(l > 1024 for l in token_lengths) / len(token_lengths) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3f7e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos la función de tokenización al conjunto de entrenamiento, validación y test.\n",
    "# Esto añade los campos necesarios para entrenar con Hugging Face (input_ids, attention_mask, etc.).\n",
    "train_data_tokenized = train_data.map(tokenizeFunction)\n",
    "valid_data_tokenized = valid_data.map(tokenizeFunction)\n",
    "test_data_tokenized = test_data.map(tokenizeFunction)\n",
    "\n",
    "# Definimos una función auxiliar para renombrar el campo \"label\" como \"labels\",\n",
    "# que es el nombre esperado por los modelos de clasificación de transformers.\n",
    "def fix_labels(example):\n",
    "    example[\"labels\"] = int(example[\"label\"])  # Aseguramos que la etiqueta sea tipo int\n",
    "    return example\n",
    "\n",
    "# Aplicamos esta corrección a los datasets tokenizados\n",
    "train_data_tokenized = train_data_tokenized.map(fix_labels)\n",
    "valid_data_tokenized = valid_data_tokenized.map(fix_labels)\n",
    "test_data_tokenized = test_data_tokenized.map(fix_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7885ab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicamos que queremos trabajar con tensores de PyTorch en lugar de listas de Python.\n",
    "# Esto es necesario para poder entrenar con `Trainer` y modelos de Hugging Face sin errores.\n",
    "\n",
    "train_data_tokenized = train_data_tokenized.with_format(\n",
    "    \"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"]\n",
    ")\n",
    "\n",
    "valid_data_tokenized = valid_data_tokenized.with_format(\n",
    "    \"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"]\n",
    ")\n",
    "\n",
    "test_data_tokenized = test_data_tokenized.with_format(\n",
    "    \"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e9bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, LongformerForSequenceClassification\n",
    "from transformers import AutoTokenizer, FillMaskPipeline\n",
    "\n",
    "# Cargamos el modelo Longformer previamente entrenado por PlanTL-GOB-ES para español,\n",
    "# adaptado a una tarea de clasificación de secuencias.\n",
    "# Especificamos que hay 2 etiquetas (misógina = 1, no misógina = 0).\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'PlanTL-GOB-ES/longformer-base-4096-bne-es',\n",
    "    num_labels=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8c0567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducimos el tamaño del conjunto de entrenamiento y validación para pruebas rápidas.\n",
    "# Esto es útil para verificar que todo el flujo de entrenamiento funciona antes de lanzarlo completo.\n",
    "\n",
    "train_data_tokenized = train_data_tokenized.select(range(20))  # Usamos solo los primeros 20 ejemplos de entrenamiento\n",
    "valid_data_tokenized = valid_data_tokenized.select(range(10))  # Usamos solo los primeros 10 ejemplos de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c474e622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "# Definimos los argumentos de entrenamiento que usará el Trainer de Hugging Face\n",
    "\n",
    "trainingArgs = TrainingArguments(\n",
    "    output_dir='outputs',                 # Carpeta donde se guardarán los modelos y checkpoints\n",
    "    num_train_epochs=5,                  # Número total de épocas de entrenamiento\n",
    "    per_device_train_batch_size=2,       # Tamaño del batch de entrenamiento por GPU/CPU\n",
    "    per_device_eval_batch_size=4,        # Tamaño del batch de evaluación (más grande ya que no hay retropropagación)\n",
    "    gradient_accumulation_steps=8,       # Acumulamos gradientes para simular batch_size efectivo de 16\n",
    "    learning_rate=2e-05,                 # Tasa de aprendizaje inicial\n",
    "    weight_decay=0.01,                   # Penalización L2 para evitar overfitting\n",
    "    eval_strategy=\"epoch\",               # Evaluamos automáticamente al final de cada época\n",
    "    logging_dir='logs',                  # Carpeta donde guardar los logs\n",
    "    load_best_model_at_end=True,         # Recuperamos el mejor modelo según eval_loss al final\n",
    "    metric_for_best_model='eval_loss',   # Usamos eval_loss como métrica principal\n",
    "    save_strategy='epoch'                # Guardamos el modelo al final de cada época\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a32db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, EarlyStoppingCallback\n",
    "\n",
    "# Inicializamos el Trainer, que se encargará de todo el proceso de entrenamiento y evaluación\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                               # Modelo de clasificación cargado (Longformer)\n",
    "    args=trainingArgs,                         # Argumentos definidos previamente\n",
    "    train_dataset=train_data_tokenized,        # Dataset de entrenamiento tokenizado\n",
    "    eval_dataset=valid_data_tokenized,         # Dataset de validación tokenizado\n",
    "\n",
    "    # Añadimos EarlyStopping para detener el entrenamiento si no mejora durante 3 evaluaciones consecutivas\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f6765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar el entrenamiento\n",
    "trainer.train()\n",
    "\n",
    "# Evaluar el modelo\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0adcb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el modelo fine-tuneado en la ruta especificada.\n",
    "# Esto incluye tanto los pesos como la configuración necesaria para volver a cargarlo después.\n",
    "\n",
    "trainer.save_model(f'{path}/models/LongformerBaseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d895e281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefinimos la función de tokenización en caso de que se haya sobrescrito o necesitemos reutilizarla.\n",
    "# Esta función:\n",
    "# - Tokeniza la letra de la canción\n",
    "# - Aplica padding y truncamiento hasta 1024 tokens\n",
    "# - Añade la máscara de atención global para Longformer (activando solo el primer token)\n",
    "\n",
    "def tokenizeFunction(example):\n",
    "    tokens = tokenizer(\n",
    "        example[COLUMN_LETRA],  # Utilizamos la columna que contiene las letras de las canciones\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=1024\n",
    "    )\n",
    "    tokens[\"global_attention_mask\"] = [0] * len(tokens[\"input_ids\"])\n",
    "    tokens[\"global_attention_mask\"][0] = 1\n",
    "    return tokens\n",
    "\n",
    "# Aplicamos nuevamente la tokenización al conjunto de test, por si se modificó o cargó sin procesar\n",
    "test_data = test_data.map(tokenizeFunction, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43e12f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Ruta donde guardaste el modelo previamente fine-tuneado\n",
    "model_path = f'{path}/models/Model_Longformer_SINCOT_LR_2e-5-Tarea_1'\n",
    "\n",
    "# Cargamos el modelo desde el directorio local donde fue guardado\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Cargamos nuevamente el tokenizador (puede usarse directamente desde Hugging Face o desde tu ruta local si lo guardaste)\n",
    "tokenizer = AutoTokenizer.from_pretrained('PlanTL-GOB-ES/longformer-base-4096-bne-es')\n",
    "\n",
    "# Creamos una nueva instancia de Trainer solo para hacer predicción\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Definimos la función de tokenización (por si aún no se había aplicado al test_data)\n",
    "def tokenizeFunction(example):\n",
    "    tokens = tokenizer(\n",
    "        example['lyrics'],           # Tokenizamos la letra\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=1024\n",
    "    )\n",
    "    tokens[\"global_attention_mask\"] = [0] * len(tokens[\"input_ids\"])\n",
    "    tokens[\"global_attention_mask\"][0] = 1\n",
    "    return tokens\n",
    "\n",
    "# Aplicamos tokenización al test set\n",
    "test_data = test_data.map(tokenizeFunction)\n",
    "\n",
    "# Hacemos la predicción usando el Trainer\n",
    "predictions = trainer.predict(test_data)\n",
    "\n",
    "# Obtenemos la etiqueta predicha (argmax sobre logits)\n",
    "predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "# Extraemos las etiquetas verdaderas desde el dataset\n",
    "true_labels = np.array(test_data['label'])\n",
    "\n",
    "# Cálculo de métricas principales\n",
    "precision = precision_score(true_labels, predicted_labels)\n",
    "recall = recall_score(true_labels, predicted_labels)\n",
    "f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "# Mostramos resultados\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-score:  {f1:.4f}\")\n",
    "\n",
    "# Matriz de confusión\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"No Misoginia\", \"Misoginia\"],\n",
    "    yticklabels=[\"No Misoginia\", \"Misoginia\"]\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix - Test Set\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
